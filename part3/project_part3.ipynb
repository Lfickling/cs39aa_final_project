{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iog5vcaz4jG"
      },
      "source": [
        "Project Part 3: A Deep Learning Model\n",
        "In this third and final part of the project you will train a deep learning model on your dataset. Note that the best way to do this will likely be to fine-tune an existing deep learning model such as GPT-2, BERT, etc. This is the same as what you will do in Assign 5, except that rather than using the Airline Tweet dataset you will be using your own dataset. Note that it is also possible to train a deep learning model from scratch with either PyTorch or TensorFlow/Keras, but that in the real world it will be more likely that you will want to leverage the cutting edge performance of a pre-trained deep learning model such as those available through huggingface. \n",
        "\n",
        "As with Parts 1 and 2, this should be done in a Jupyter notebook and you should add the notebook to the repository where Assign 1 and 2 are. When you are done, you will then get the URL of your project_part3.ipynb notebook in your GitHub repository, and submit that URL here in Canvas. \n",
        "\n",
        "Note: Be sure that the output from each cell in you your notebook files is saved to the .ipynb file before your final commit and upload to your GitHub repository.\n",
        "\n",
        " \n",
        "\n",
        "If you are working with a more challenging NLP task such as text summarization or text generation, then Part 3 should be where you fine tune an existing deep learning model for your task (ex: our notebook on text generation w/ GPT-2 fine tuned on Hemingway Links to an external site.). Whereas, Part 2 should be where you used a pre-trained model out of the box without fine tuning it on your dataset (ex: our notebook on text generation w/ a pre-trained GPT-2 model Links to an external site.). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrGM8CgDBJjs",
        "outputId": "b7e02d47-b469-48bc-cb70-aeebdde47794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 80.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 75.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 100.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 85.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 87.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 82.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 98.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 114.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 109.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 108.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 90.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 91.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 90.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 85.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 85.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 89.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEYGTfDRBTvs",
        "outputId": "0bdba7a6-b273-46b2-ca05-c06e3e2c813c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1Jur49r00X3",
        "outputId": "f742c7f2-2f21-4fbb-b0a7-cf2a81b3573c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YeC_f8_Rz4jN"
      },
      "outputs": [],
      "source": [
        "# import all of the python modules/packages you'll need here\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIBMcFDm2eRL",
        "outputId": "d9674bd1-31a3-4ef8-b0e7-f41eca8a6700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--gpt2-medium/snapshots/e852c9080bc759a01663acf5a828d95b261a9903/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--gpt2-medium/snapshots/e852c9080bc759a01663acf5a828d95b261a9903/merges.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2-medium/snapshots/e852c9080bc759a01663acf5a828d95b261a9903/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2-medium\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Adding <|startoftext|> to the vocabulary\n",
            "Adding <|pad|> to the vocabulary\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2-medium/snapshots/e852c9080bc759a01663acf5a828d95b261a9903/config.json\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--gpt2-medium/snapshots/e852c9080bc759a01663acf5a828d95b261a9903/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2-medium.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50259, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "MODEL_NAME = \"gpt2-medium\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
        "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17_Jr27M_qJV",
        "outputId": "58bafcc4-cfb3-4365-8880-90bc0ef55d2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wte.weight True\n",
            "wpe.weight True\n",
            "h.0.ln_1.weight True\n",
            "h.0.ln_1.bias True\n",
            "h.0.attn.c_attn.weight True\n",
            "h.0.attn.c_attn.bias True\n",
            "h.0.attn.c_proj.weight True\n",
            "h.0.attn.c_proj.bias True\n",
            "h.0.ln_2.weight True\n",
            "h.0.ln_2.bias True\n",
            "h.0.mlp.c_fc.weight True\n",
            "h.0.mlp.c_fc.bias True\n",
            "h.0.mlp.c_proj.weight True\n",
            "h.0.mlp.c_proj.bias True\n",
            "h.1.ln_1.weight True\n",
            "h.1.ln_1.bias True\n",
            "h.1.attn.c_attn.weight True\n",
            "h.1.attn.c_attn.bias True\n",
            "h.1.attn.c_proj.weight True\n",
            "h.1.attn.c_proj.bias True\n",
            "h.1.ln_2.weight True\n",
            "h.1.ln_2.bias True\n",
            "h.1.mlp.c_fc.weight True\n",
            "h.1.mlp.c_fc.bias True\n",
            "h.1.mlp.c_proj.weight True\n",
            "h.1.mlp.c_proj.bias True\n",
            "h.2.ln_1.weight True\n",
            "h.2.ln_1.bias True\n",
            "h.2.attn.c_attn.weight True\n",
            "h.2.attn.c_attn.bias True\n",
            "h.2.attn.c_proj.weight True\n",
            "h.2.attn.c_proj.bias True\n",
            "h.2.ln_2.weight True\n",
            "h.2.ln_2.bias True\n",
            "h.2.mlp.c_fc.weight True\n",
            "h.2.mlp.c_fc.bias True\n",
            "h.2.mlp.c_proj.weight True\n",
            "h.2.mlp.c_proj.bias True\n",
            "h.3.ln_1.weight True\n",
            "h.3.ln_1.bias True\n",
            "h.3.attn.c_attn.weight True\n",
            "h.3.attn.c_attn.bias True\n",
            "h.3.attn.c_proj.weight True\n",
            "h.3.attn.c_proj.bias True\n",
            "h.3.ln_2.weight True\n",
            "h.3.ln_2.bias True\n",
            "h.3.mlp.c_fc.weight True\n",
            "h.3.mlp.c_fc.bias True\n",
            "h.3.mlp.c_proj.weight True\n",
            "h.3.mlp.c_proj.bias True\n",
            "h.4.ln_1.weight True\n",
            "h.4.ln_1.bias True\n",
            "h.4.attn.c_attn.weight True\n",
            "h.4.attn.c_attn.bias True\n",
            "h.4.attn.c_proj.weight True\n",
            "h.4.attn.c_proj.bias True\n",
            "h.4.ln_2.weight True\n",
            "h.4.ln_2.bias True\n",
            "h.4.mlp.c_fc.weight True\n",
            "h.4.mlp.c_fc.bias True\n",
            "h.4.mlp.c_proj.weight True\n",
            "h.4.mlp.c_proj.bias True\n",
            "h.5.ln_1.weight True\n",
            "h.5.ln_1.bias True\n",
            "h.5.attn.c_attn.weight True\n",
            "h.5.attn.c_attn.bias True\n",
            "h.5.attn.c_proj.weight True\n",
            "h.5.attn.c_proj.bias True\n",
            "h.5.ln_2.weight True\n",
            "h.5.ln_2.bias True\n",
            "h.5.mlp.c_fc.weight True\n",
            "h.5.mlp.c_fc.bias True\n",
            "h.5.mlp.c_proj.weight True\n",
            "h.5.mlp.c_proj.bias True\n",
            "h.6.ln_1.weight True\n",
            "h.6.ln_1.bias True\n",
            "h.6.attn.c_attn.weight True\n",
            "h.6.attn.c_attn.bias True\n",
            "h.6.attn.c_proj.weight True\n",
            "h.6.attn.c_proj.bias True\n",
            "h.6.ln_2.weight True\n",
            "h.6.ln_2.bias True\n",
            "h.6.mlp.c_fc.weight True\n",
            "h.6.mlp.c_fc.bias True\n",
            "h.6.mlp.c_proj.weight True\n",
            "h.6.mlp.c_proj.bias True\n",
            "h.7.ln_1.weight True\n",
            "h.7.ln_1.bias True\n",
            "h.7.attn.c_attn.weight True\n",
            "h.7.attn.c_attn.bias True\n",
            "h.7.attn.c_proj.weight True\n",
            "h.7.attn.c_proj.bias True\n",
            "h.7.ln_2.weight True\n",
            "h.7.ln_2.bias True\n",
            "h.7.mlp.c_fc.weight True\n",
            "h.7.mlp.c_fc.bias True\n",
            "h.7.mlp.c_proj.weight True\n",
            "h.7.mlp.c_proj.bias True\n",
            "h.8.ln_1.weight True\n",
            "h.8.ln_1.bias True\n",
            "h.8.attn.c_attn.weight True\n",
            "h.8.attn.c_attn.bias True\n",
            "h.8.attn.c_proj.weight True\n",
            "h.8.attn.c_proj.bias True\n",
            "h.8.ln_2.weight True\n",
            "h.8.ln_2.bias True\n",
            "h.8.mlp.c_fc.weight True\n",
            "h.8.mlp.c_fc.bias True\n",
            "h.8.mlp.c_proj.weight True\n",
            "h.8.mlp.c_proj.bias True\n",
            "h.9.ln_1.weight True\n",
            "h.9.ln_1.bias True\n",
            "h.9.attn.c_attn.weight True\n",
            "h.9.attn.c_attn.bias True\n",
            "h.9.attn.c_proj.weight True\n",
            "h.9.attn.c_proj.bias True\n",
            "h.9.ln_2.weight True\n",
            "h.9.ln_2.bias True\n",
            "h.9.mlp.c_fc.weight True\n",
            "h.9.mlp.c_fc.bias True\n",
            "h.9.mlp.c_proj.weight True\n",
            "h.9.mlp.c_proj.bias True\n",
            "h.10.ln_1.weight True\n",
            "h.10.ln_1.bias True\n",
            "h.10.attn.c_attn.weight True\n",
            "h.10.attn.c_attn.bias True\n",
            "h.10.attn.c_proj.weight True\n",
            "h.10.attn.c_proj.bias True\n",
            "h.10.ln_2.weight True\n",
            "h.10.ln_2.bias True\n",
            "h.10.mlp.c_fc.weight True\n",
            "h.10.mlp.c_fc.bias True\n",
            "h.10.mlp.c_proj.weight True\n",
            "h.10.mlp.c_proj.bias True\n",
            "h.11.ln_1.weight True\n",
            "h.11.ln_1.bias True\n",
            "h.11.attn.c_attn.weight True\n",
            "h.11.attn.c_attn.bias True\n",
            "h.11.attn.c_proj.weight True\n",
            "h.11.attn.c_proj.bias True\n",
            "h.11.ln_2.weight True\n",
            "h.11.ln_2.bias True\n",
            "h.11.mlp.c_fc.weight True\n",
            "h.11.mlp.c_fc.bias True\n",
            "h.11.mlp.c_proj.weight True\n",
            "h.11.mlp.c_proj.bias True\n",
            "h.12.ln_1.weight True\n",
            "h.12.ln_1.bias True\n",
            "h.12.attn.c_attn.weight True\n",
            "h.12.attn.c_attn.bias True\n",
            "h.12.attn.c_proj.weight True\n",
            "h.12.attn.c_proj.bias True\n",
            "h.12.ln_2.weight True\n",
            "h.12.ln_2.bias True\n",
            "h.12.mlp.c_fc.weight True\n",
            "h.12.mlp.c_fc.bias True\n",
            "h.12.mlp.c_proj.weight True\n",
            "h.12.mlp.c_proj.bias True\n",
            "h.13.ln_1.weight True\n",
            "h.13.ln_1.bias True\n",
            "h.13.attn.c_attn.weight True\n",
            "h.13.attn.c_attn.bias True\n",
            "h.13.attn.c_proj.weight True\n",
            "h.13.attn.c_proj.bias True\n",
            "h.13.ln_2.weight True\n",
            "h.13.ln_2.bias True\n",
            "h.13.mlp.c_fc.weight True\n",
            "h.13.mlp.c_fc.bias True\n",
            "h.13.mlp.c_proj.weight True\n",
            "h.13.mlp.c_proj.bias True\n",
            "h.14.ln_1.weight True\n",
            "h.14.ln_1.bias True\n",
            "h.14.attn.c_attn.weight True\n",
            "h.14.attn.c_attn.bias True\n",
            "h.14.attn.c_proj.weight True\n",
            "h.14.attn.c_proj.bias True\n",
            "h.14.ln_2.weight True\n",
            "h.14.ln_2.bias True\n",
            "h.14.mlp.c_fc.weight True\n",
            "h.14.mlp.c_fc.bias True\n",
            "h.14.mlp.c_proj.weight True\n",
            "h.14.mlp.c_proj.bias True\n",
            "h.15.ln_1.weight True\n",
            "h.15.ln_1.bias True\n",
            "h.15.attn.c_attn.weight True\n",
            "h.15.attn.c_attn.bias True\n",
            "h.15.attn.c_proj.weight True\n",
            "h.15.attn.c_proj.bias True\n",
            "h.15.ln_2.weight True\n",
            "h.15.ln_2.bias True\n",
            "h.15.mlp.c_fc.weight True\n",
            "h.15.mlp.c_fc.bias True\n",
            "h.15.mlp.c_proj.weight True\n",
            "h.15.mlp.c_proj.bias True\n",
            "h.16.ln_1.weight True\n",
            "h.16.ln_1.bias True\n",
            "h.16.attn.c_attn.weight True\n",
            "h.16.attn.c_attn.bias True\n",
            "h.16.attn.c_proj.weight True\n",
            "h.16.attn.c_proj.bias True\n",
            "h.16.ln_2.weight True\n",
            "h.16.ln_2.bias True\n",
            "h.16.mlp.c_fc.weight True\n",
            "h.16.mlp.c_fc.bias True\n",
            "h.16.mlp.c_proj.weight True\n",
            "h.16.mlp.c_proj.bias True\n",
            "h.17.ln_1.weight True\n",
            "h.17.ln_1.bias True\n",
            "h.17.attn.c_attn.weight True\n",
            "h.17.attn.c_attn.bias True\n",
            "h.17.attn.c_proj.weight True\n",
            "h.17.attn.c_proj.bias True\n",
            "h.17.ln_2.weight True\n",
            "h.17.ln_2.bias True\n",
            "h.17.mlp.c_fc.weight True\n",
            "h.17.mlp.c_fc.bias True\n",
            "h.17.mlp.c_proj.weight True\n",
            "h.17.mlp.c_proj.bias True\n",
            "h.18.ln_1.weight True\n",
            "h.18.ln_1.bias True\n",
            "h.18.attn.c_attn.weight True\n",
            "h.18.attn.c_attn.bias True\n",
            "h.18.attn.c_proj.weight True\n",
            "h.18.attn.c_proj.bias True\n",
            "h.18.ln_2.weight True\n",
            "h.18.ln_2.bias True\n",
            "h.18.mlp.c_fc.weight True\n",
            "h.18.mlp.c_fc.bias True\n",
            "h.18.mlp.c_proj.weight True\n",
            "h.18.mlp.c_proj.bias True\n",
            "h.19.ln_1.weight True\n",
            "h.19.ln_1.bias True\n",
            "h.19.attn.c_attn.weight True\n",
            "h.19.attn.c_attn.bias True\n",
            "h.19.attn.c_proj.weight True\n",
            "h.19.attn.c_proj.bias True\n",
            "h.19.ln_2.weight True\n",
            "h.19.ln_2.bias True\n",
            "h.19.mlp.c_fc.weight True\n",
            "h.19.mlp.c_fc.bias True\n",
            "h.19.mlp.c_proj.weight True\n",
            "h.19.mlp.c_proj.bias True\n",
            "h.20.ln_1.weight True\n",
            "h.20.ln_1.bias True\n",
            "h.20.attn.c_attn.weight True\n",
            "h.20.attn.c_attn.bias True\n",
            "h.20.attn.c_proj.weight True\n",
            "h.20.attn.c_proj.bias True\n",
            "h.20.ln_2.weight True\n",
            "h.20.ln_2.bias True\n",
            "h.20.mlp.c_fc.weight True\n",
            "h.20.mlp.c_fc.bias True\n",
            "h.20.mlp.c_proj.weight True\n",
            "h.20.mlp.c_proj.bias True\n",
            "h.21.ln_1.weight True\n",
            "h.21.ln_1.bias True\n",
            "h.21.attn.c_attn.weight True\n",
            "h.21.attn.c_attn.bias True\n",
            "h.21.attn.c_proj.weight True\n",
            "h.21.attn.c_proj.bias True\n",
            "h.21.ln_2.weight True\n",
            "h.21.ln_2.bias True\n",
            "h.21.mlp.c_fc.weight True\n",
            "h.21.mlp.c_fc.bias True\n",
            "h.21.mlp.c_proj.weight True\n",
            "h.21.mlp.c_proj.bias True\n",
            "h.22.ln_1.weight True\n",
            "h.22.ln_1.bias True\n",
            "h.22.attn.c_attn.weight True\n",
            "h.22.attn.c_attn.bias True\n",
            "h.22.attn.c_proj.weight True\n",
            "h.22.attn.c_proj.bias True\n",
            "h.22.ln_2.weight True\n",
            "h.22.ln_2.bias True\n",
            "h.22.mlp.c_fc.weight True\n",
            "h.22.mlp.c_fc.bias True\n",
            "h.22.mlp.c_proj.weight True\n",
            "h.22.mlp.c_proj.bias True\n",
            "h.23.ln_1.weight True\n",
            "h.23.ln_1.bias True\n",
            "h.23.attn.c_attn.weight True\n",
            "h.23.attn.c_attn.bias True\n",
            "h.23.attn.c_proj.weight True\n",
            "h.23.attn.c_proj.bias True\n",
            "h.23.ln_2.weight True\n",
            "h.23.ln_2.bias True\n",
            "h.23.mlp.c_fc.weight True\n",
            "h.23.mlp.c_fc.bias True\n",
            "h.23.mlp.c_proj.weight True\n",
            "h.23.mlp.c_proj.bias True\n",
            "h.24.ln_1.weight True\n",
            "h.24.ln_1.bias True\n",
            "h.24.attn.c_attn.weight True\n",
            "h.24.attn.c_attn.bias True\n",
            "h.24.attn.c_proj.weight True\n",
            "h.24.attn.c_proj.bias True\n",
            "h.24.ln_2.weight True\n",
            "h.24.ln_2.bias True\n",
            "h.24.mlp.c_fc.weight True\n",
            "h.24.mlp.c_fc.bias True\n",
            "h.24.mlp.c_proj.weight True\n",
            "h.24.mlp.c_proj.bias True\n",
            "h.25.ln_1.weight True\n",
            "h.25.ln_1.bias True\n",
            "h.25.attn.c_attn.weight True\n",
            "h.25.attn.c_attn.bias True\n",
            "h.25.attn.c_proj.weight True\n",
            "h.25.attn.c_proj.bias True\n",
            "h.25.ln_2.weight True\n",
            "h.25.ln_2.bias True\n",
            "h.25.mlp.c_fc.weight True\n",
            "h.25.mlp.c_fc.bias True\n",
            "h.25.mlp.c_proj.weight True\n",
            "h.25.mlp.c_proj.bias True\n",
            "h.26.ln_1.weight True\n",
            "h.26.ln_1.bias True\n",
            "h.26.attn.c_attn.weight True\n",
            "h.26.attn.c_attn.bias True\n",
            "h.26.attn.c_proj.weight True\n",
            "h.26.attn.c_proj.bias True\n",
            "h.26.ln_2.weight True\n",
            "h.26.ln_2.bias True\n",
            "h.26.mlp.c_fc.weight True\n",
            "h.26.mlp.c_fc.bias True\n",
            "h.26.mlp.c_proj.weight True\n",
            "h.26.mlp.c_proj.bias True\n",
            "h.27.ln_1.weight True\n",
            "h.27.ln_1.bias True\n",
            "h.27.attn.c_attn.weight True\n",
            "h.27.attn.c_attn.bias True\n",
            "h.27.attn.c_proj.weight True\n",
            "h.27.attn.c_proj.bias True\n",
            "h.27.ln_2.weight True\n",
            "h.27.ln_2.bias True\n",
            "h.27.mlp.c_fc.weight True\n",
            "h.27.mlp.c_fc.bias True\n",
            "h.27.mlp.c_proj.weight True\n",
            "h.27.mlp.c_proj.bias True\n",
            "h.28.ln_1.weight True\n",
            "h.28.ln_1.bias True\n",
            "h.28.attn.c_attn.weight True\n",
            "h.28.attn.c_attn.bias True\n",
            "h.28.attn.c_proj.weight True\n",
            "h.28.attn.c_proj.bias True\n",
            "h.28.ln_2.weight True\n",
            "h.28.ln_2.bias True\n",
            "h.28.mlp.c_fc.weight True\n",
            "h.28.mlp.c_fc.bias True\n",
            "h.28.mlp.c_proj.weight True\n",
            "h.28.mlp.c_proj.bias True\n",
            "h.29.ln_1.weight True\n",
            "h.29.ln_1.bias True\n",
            "h.29.attn.c_attn.weight True\n",
            "h.29.attn.c_attn.bias True\n",
            "h.29.attn.c_proj.weight True\n",
            "h.29.attn.c_proj.bias True\n",
            "h.29.ln_2.weight True\n",
            "h.29.ln_2.bias True\n",
            "h.29.mlp.c_fc.weight True\n",
            "h.29.mlp.c_fc.bias True\n",
            "h.29.mlp.c_proj.weight True\n",
            "h.29.mlp.c_proj.bias True\n",
            "h.30.ln_1.weight True\n",
            "h.30.ln_1.bias True\n",
            "h.30.attn.c_attn.weight True\n",
            "h.30.attn.c_attn.bias True\n",
            "h.30.attn.c_proj.weight True\n",
            "h.30.attn.c_proj.bias True\n",
            "h.30.ln_2.weight True\n",
            "h.30.ln_2.bias True\n",
            "h.30.mlp.c_fc.weight True\n",
            "h.30.mlp.c_fc.bias True\n",
            "h.30.mlp.c_proj.weight True\n",
            "h.30.mlp.c_proj.bias True\n",
            "h.31.ln_1.weight True\n",
            "h.31.ln_1.bias True\n",
            "h.31.attn.c_attn.weight True\n",
            "h.31.attn.c_attn.bias True\n",
            "h.31.attn.c_proj.weight True\n",
            "h.31.attn.c_proj.bias True\n",
            "h.31.ln_2.weight True\n",
            "h.31.ln_2.bias True\n",
            "h.31.mlp.c_fc.weight True\n",
            "h.31.mlp.c_fc.bias True\n",
            "h.31.mlp.c_proj.weight True\n",
            "h.31.mlp.c_proj.bias True\n",
            "h.32.ln_1.weight True\n",
            "h.32.ln_1.bias True\n",
            "h.32.attn.c_attn.weight True\n",
            "h.32.attn.c_attn.bias True\n",
            "h.32.attn.c_proj.weight True\n",
            "h.32.attn.c_proj.bias True\n",
            "h.32.ln_2.weight True\n",
            "h.32.ln_2.bias True\n",
            "h.32.mlp.c_fc.weight True\n",
            "h.32.mlp.c_fc.bias True\n",
            "h.32.mlp.c_proj.weight True\n",
            "h.32.mlp.c_proj.bias True\n",
            "h.33.ln_1.weight True\n",
            "h.33.ln_1.bias True\n",
            "h.33.attn.c_attn.weight True\n",
            "h.33.attn.c_attn.bias True\n",
            "h.33.attn.c_proj.weight True\n",
            "h.33.attn.c_proj.bias True\n",
            "h.33.ln_2.weight True\n",
            "h.33.ln_2.bias True\n",
            "h.33.mlp.c_fc.weight True\n",
            "h.33.mlp.c_fc.bias True\n",
            "h.33.mlp.c_proj.weight True\n",
            "h.33.mlp.c_proj.bias True\n",
            "h.34.ln_1.weight True\n",
            "h.34.ln_1.bias True\n",
            "h.34.attn.c_attn.weight True\n",
            "h.34.attn.c_attn.bias True\n",
            "h.34.attn.c_proj.weight True\n",
            "h.34.attn.c_proj.bias True\n",
            "h.34.ln_2.weight True\n",
            "h.34.ln_2.bias True\n",
            "h.34.mlp.c_fc.weight True\n",
            "h.34.mlp.c_fc.bias True\n",
            "h.34.mlp.c_proj.weight True\n",
            "h.34.mlp.c_proj.bias True\n",
            "h.35.ln_1.weight True\n",
            "h.35.ln_1.bias True\n",
            "h.35.attn.c_attn.weight True\n",
            "h.35.attn.c_attn.bias True\n",
            "h.35.attn.c_proj.weight True\n",
            "h.35.attn.c_proj.bias True\n",
            "h.35.ln_2.weight True\n",
            "h.35.ln_2.bias True\n",
            "h.35.mlp.c_fc.weight True\n",
            "h.35.mlp.c_fc.bias True\n",
            "h.35.mlp.c_proj.weight True\n",
            "h.35.mlp.c_proj.bias True\n",
            "ln_f.weight True\n",
            "ln_f.bias True\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HTMtihFe79qY",
        "outputId": "b062e991-1d35-4bc4-acaf-39eb2f9a9095"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       title                      author  \\\n",
              "0     Harry Potter and the Half-Blood Prince                J.K. Rowling   \n",
              "1  Harry Potter and the Order of the Phoenix  J.K. Rowling,Mary GrandPré   \n",
              "2    Harry Potter and the Chamber of Secrets                J.K. Rowling   \n",
              "3   Harry Potter and the Prisoner of Azkaban  J.K. Rowling,Mary GrandPré   \n",
              "4        Harry Potter and the Goblet of Fire  J.K. Rowling,Mary GrandPré   \n",
              "\n",
              "                                         description language  characterCount  \\\n",
              "0  The war against Voldemort is not going well; e...  English            1239   \n",
              "1  There is a door at the end of a silent corrido...  English            1185   \n",
              "2  The Dursleys were so mean and hideous that sum...  English            1342   \n",
              "3  For twelve long years, the dread fortress of A...  English            1014   \n",
              "4  Harry Potter is midway through his training as...  English            1052   \n",
              "\n",
              "   wordCount                                descriptionAndTitle  \n",
              "0        205  Harry Potter and the Half-Blood Prince The war...  \n",
              "1        204  Harry Potter and the Order of the Phoenix Ther...  \n",
              "2        222  Harry Potter and the Chamber of Secrets The Du...  \n",
              "3        176  Harry Potter and the Prisoner of Azkaban For t...  \n",
              "4        184  Harry Potter and the Goblet of Fire Harry Pott...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85a3b5e1-c36e-4e14-9180-f34645e6a8b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>description</th>\n",
              "      <th>language</th>\n",
              "      <th>characterCount</th>\n",
              "      <th>wordCount</th>\n",
              "      <th>descriptionAndTitle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Harry Potter and the Half-Blood Prince</td>\n",
              "      <td>J.K. Rowling</td>\n",
              "      <td>The war against Voldemort is not going well; e...</td>\n",
              "      <td>English</td>\n",
              "      <td>1239</td>\n",
              "      <td>205</td>\n",
              "      <td>Harry Potter and the Half-Blood Prince The war...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Harry Potter and the Order of the Phoenix</td>\n",
              "      <td>J.K. Rowling,Mary GrandPré</td>\n",
              "      <td>There is a door at the end of a silent corrido...</td>\n",
              "      <td>English</td>\n",
              "      <td>1185</td>\n",
              "      <td>204</td>\n",
              "      <td>Harry Potter and the Order of the Phoenix Ther...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Harry Potter and the Chamber of Secrets</td>\n",
              "      <td>J.K. Rowling</td>\n",
              "      <td>The Dursleys were so mean and hideous that sum...</td>\n",
              "      <td>English</td>\n",
              "      <td>1342</td>\n",
              "      <td>222</td>\n",
              "      <td>Harry Potter and the Chamber of Secrets The Du...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
              "      <td>J.K. Rowling,Mary GrandPré</td>\n",
              "      <td>For twelve long years, the dread fortress of A...</td>\n",
              "      <td>English</td>\n",
              "      <td>1014</td>\n",
              "      <td>176</td>\n",
              "      <td>Harry Potter and the Prisoner of Azkaban For t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Harry Potter and the Goblet of Fire</td>\n",
              "      <td>J.K. Rowling,Mary GrandPré</td>\n",
              "      <td>Harry Potter is midway through his training as...</td>\n",
              "      <td>English</td>\n",
              "      <td>1052</td>\n",
              "      <td>184</td>\n",
              "      <td>Harry Potter and the Goblet of Fire Harry Pott...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85a3b5e1-c36e-4e14-9180-f34645e6a8b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85a3b5e1-c36e-4e14-9180-f34645e6a8b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85a3b5e1-c36e-4e14-9180-f34645e6a8b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "books= pd.read_csv('books_clean_3.csv')\n",
        "books.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books = books[books['wordCount'] <= 200]\n",
        "len(books)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMDX5L8wiq02",
        "outputId": "0a2e109e-ba4d-4c8b-a3c2-cc4bf4cfdaf3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10324"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASs1cNnR7YJZ",
        "outputId": "0c03880b-62f6-4343-ab12-37eac9eaa888"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    Harry Potter and the Prisoner of Azkaban For t...\n",
              "4    Harry Potter and the Goblet of Fire Harry Pott...\n",
              "5    Harry Potter Boxed Set, Books 1-5 (Harry Potte...\n",
              "6    Unauthorized Harry Potter Book Seven News: \\\"H...\n",
              "7    Harry Potter Collection Six years of magic, ad...\n",
              "Name: descriptionAndTitle, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "descriptions = books['descriptionAndTitle']\n",
        "descriptions.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlLwk3nx7mAp",
        "outputId": "fcd10fdd-4afc-403b-a14f-61e6be3006e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2352 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "max_length = max([len(tokenizer.encode(description)) for description in descriptions])\n",
        "if tokenizer.model_max_length < max_length:\n",
        "  max_length = tokenizer.model_max_length\n",
        "max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z8NclnzIJyN",
        "outputId": "f269339e-2642-4821-cc60-d4c066591538"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "OGeOtzuC7syr"
      },
      "outputs": [],
      "source": [
        "class DescriptionDataset(Dataset):\n",
        "    def __init__(self, txt_list, tokenizer, max_length):\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        self.labels = []\n",
        "        for txt in txt_list:\n",
        "            encodings_dict = tokenizer('<|startoftext|>' + txt + '<|endoftext|>', truncation=True,\n",
        "                                       max_length=512, padding=\"max_length\")\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "WxrWcPAiz4jP"
      },
      "outputs": [],
      "source": [
        "dataset = DescriptionDataset(descriptions, tokenizer, max_length=max_length)\n",
        "train_size = int(0.75 * len(dataset))\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZq0wmxm-H-9",
        "outputId": "e4a2e39d-dfdd-4f78-9f19-81c0b88ae7f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([50257, 13448, 47776,  3454, 32452,   262,  5426,   318, 17157,   319,\n",
              "         15827,   532,   290,  5295,   284,  2222,  1918,   290,  8166,   284,\n",
              "          2297, 11930,    13, 36397,   465,  6181,  4097,  1088,   683,    11,\n",
              "          3454, 32452, 21528,   284,  5587,   379,   262,  2612,   286,   262,\n",
              "         33128,    13,  2399, 34218,   290, 47687,  1410,   318,   284,  8711,\n",
              "           262,  2297, 11930,  1751,   532,   290,  4705, 47776,    11, 45524,\n",
              "          4448,   338,  3367,    11,   318,   284,   307,    11, 11122, 32452,\n",
              "           262,  5426,   318, 17157,   319, 15827,   532,   290,  5295,   284,\n",
              "          2222,  1918,   290,  8166,   284,  2297, 11930,    13, 36397,   465,\n",
              "          6181,  4097,  1088,   683,    11,  3454, 32452, 21528,   284,  5587,\n",
              "           379,   262,  2612,   286,   262, 33128,    13,  2399, 34218,   290,\n",
              "         47687,  1410,   318,   284,  8711,   262,  2297, 11930,  1751,   532,\n",
              "           290,  4705, 47776,    11, 45524,  4448,   338,  3367,    11,   318,\n",
              "           284,   307,   262,  4094, 11596,   286,   477,   764,   764,   764,\n",
              "         50256, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
              "         50258, 50258]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuDZMsiu-LDb",
        "outputId": "43011180-ba30-4973-be6d-e24c87d37e06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30830"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Z_neG9UpLj3T",
        "outputId": "52d24114-dfc7-4de0-ce69-db0b3af44b12"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:2bw3lpw4) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">crisp-fog-15</strong>: <a href=\"https://wandb.ai/lfickling/project_part_3/runs/2bw3lpw4\" target=\"_blank\">https://wandb.ai/lfickling/project_part_3/runs/2bw3lpw4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221208_161757-2bw3lpw4/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:2bw3lpw4). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221208_162255-i6ebvvcd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/lfickling/project_part_3/runs/i6ebvvcd\" target=\"_blank\">apricot-forest-16</a></strong> to <a href=\"https://wandb.ai/lfickling/project_part_3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.init(\n",
        "        project=\"project_part_3\",\n",
        "        config={\n",
        "            \"epochs\": 5,\n",
        "            \"batch_size\": 20,\n",
        "            \"lr\": 1e-3,\n",
        "            #\"dropout\": random.uniform(0.01, 0.80),\n",
        "            })\n",
        "    \n",
        "    # Copy your config \n",
        "config = wandb.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrRXNsja-OKC"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(output_dir='/results',\n",
        "                                  num_train_epochs=config.epochs,\n",
        "                                  learning_rate=config.lr,\n",
        "                                  per_device_train_batch_size=config.batch_size,\n",
        "                                  per_device_eval_batch_size=16,\n",
        "                                  save_strategy='epoch',\n",
        "                                  evaluation_strategy='epoch',\n",
        "                                  logging_strategy='epoch',\n",
        "                                  remove_unused_columns=True,\n",
        "                                  no_cuda=False,\n",
        "                                  #logging_steps=100,\n",
        "                                  #save_steps=5000,                                   \n",
        "                                  #warmup_steps=10,\n",
        "                                  #weight_decay=config.weight_decay, \n",
        "                                  #logging_dir='/logs',\n",
        "                                  load_best_model_at_end=True,\n",
        "                                  report_to = 'wandb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "8PikOL1cNzPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "011dfc0d-44ea-4e21-ce54-c7936895cba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(output_dir='/results',\n",
        "                                  num_train_epochs=1,\n",
        "                                  logging_steps=100,\n",
        "                                  save_steps=5000,                                   \n",
        "                                  per_device_train_batch_size=1,\n",
        "                                  per_device_eval_batch_size=1,\n",
        "                                  warmup_steps=10,\n",
        "                                  weight_decay=0.05,  \n",
        "                                  logging_dir='/logs',\n",
        "                                  report_to = 'wandb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "XFui4D3v-SIe"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model=model, args=training_args,  \n",
        "                  train_dataset=train_dataset,\n",
        "                  eval_dataset=val_dataset, \n",
        "                  # This custom collate function is necessary \n",
        "                  # to built batches of data\n",
        "                  data_collator=lambda data: \n",
        "                  {'input_ids': torch.stack([f[0] for f in data]),       \n",
        "                  'attention_mask': torch.stack([f[1] for f in data]),\n",
        "                  'labels': torch.stack([f[0] for f in data])})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkjQaXFDPKUf"
      },
      "source": [
        "TrainOutput(global_step=6057, training_loss=0.5333825958942213, metrics={'train_runtime': 3561.2552, 'train_samples_per_second': 1.701, 'train_steps_per_second': 1.701, 'total_flos': 5625140106756096.0, 'train_loss': 0.5333825958942213, 'epoch': 1.0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_n2l3gPSB3W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Py50XU_M-WwT",
        "outputId": "b477141e-df4b-42f4-9c58-256a034ba328"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 9291\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 9291\n",
            "  Number of trainable parameters = 354825216\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='451' max='9291' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 451/9291 04:08 < 1:21:25, 1.81 it/s, Epoch 0.05/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.834700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.841500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.820200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.748300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9291' max='9291' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9291/9291 1:25:57, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.834700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.841500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.820200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.748300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.780700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.776200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.783900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.765200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.788100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.751200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.763400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.800500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.767400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.797700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.836400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.741000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.760500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.777100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.803800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.782800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.870100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.742100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.831800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.814400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.765000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.761200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.830900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.772400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.739600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.710600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.752700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.799900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.687000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.745300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.792400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.700600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.796500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.704000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.707700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.721300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.746900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.724300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.758400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.747500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.708600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.755400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.711100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.714900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.698100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.702200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.779200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.716500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.730400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.773400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.659500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.718200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.747500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.702600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.718200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.718800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.730400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.736700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.730500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.747900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.698400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.714700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.716400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.752400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.743900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.774400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.764700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.759100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.757000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.759800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.724000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.794400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.733900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.755600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.782800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.750600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.769000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.718900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.734700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.808100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.722400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.710500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.720700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.736300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.736100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.667500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.747900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.705000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /results/checkpoint-5000\n",
            "Configuration saved in /results/checkpoint-5000/config.json\n",
            "Model weights saved in /results/checkpoint-5000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=9291, training_loss=0.7728254523321934, metrics={'train_runtime': 5158.5235, 'train_samples_per_second': 1.801, 'train_steps_per_second': 1.801, 'total_flos': 8628558152859648.0, 'train_loss': 0.7728254523321934, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Start training process!\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/models\")\n",
        "tokenizer.save_pretrained(\"/models\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"/models\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"/models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4qpdWv7my5C",
        "outputId": "b13f1394-735a-4116-86ea-7de142f72427"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /models/config.json\n",
            "Model weights saved in /models/pytorch_model.bin\n",
            "tokenizer config file saved in /models/tokenizer_config.json\n",
            "Special tokens file saved in /models/special_tokens_map.json\n",
            "added tokens file saved in /models/added_tokens.json\n",
            "loading file vocab.json\n",
            "loading file merges.txt\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Adding <|startoftext|> to the vocabulary\n",
            "Adding <|pad|> to the vocabulary\n",
            "loading configuration file /models/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2-medium\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50259\n",
            "}\n",
            "\n",
            "loading weights file /models/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /models.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated = tokenizer(\"<|startoftext|> Harry Potter and The Half-Blood Prince\", return_tensors=\"pt\").input_ids\n",
        "sample_outputs = model.generate(generated, no_repeat_ngram_size=2, do_sample=True, top_k=50, max_length=100, top_p=0.95, temperature=0.5, num_return_sequences=3)\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz8qjg8Dm-Fb",
        "outputId": "74aec12f-62ae-4ed3-b113-5d1b6a667139"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:  Harry Potter and The Half-Blood Prince Harry and his friends are given a chance to test their mettle against the Dark Lord Voldemort. But will they be able to defeat the powerful wizard and save the world?\n",
            "1:  Harry Potter and The Half-Blood Prince Harry's first adventure as a wizard begins. In this magical world, the most powerful wizard in the world is a boy named Voldemort. Harry must fight to defeat him, and learn the true meaning of his destiny.\n",
            "2:  Harry Potter and The Half-Blood Prince Harry and his friends are in trouble when a mysterious, black-haired boy appears in their midst. The boy is Harry's best friend, Ron. But Ron is a wizard, and Harry is not. And Ron's magic is no match for Harry, who is,Harry and their friends were in danger when an mysterious,,black-headed boy appeared in our midst.,Harry is in Trouble whena mysterious black hair boy emerges in your midst, threatening to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7MFvzQSKB0I"
      },
      "outputs": [],
      "source": [
        "# 🐝 Close your wandb run \n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXyGwqM0z4jQ"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 3.5))\n",
        "\n",
        "axes[0].hist(probs[0], bins=np.logspace(-10, -1, 100), color=\"C0\", edgecolor=\"C0\")\n",
        "axes[0].set_xscale(\"log\")\n",
        "axes[0].set_yscale(\"log\")\n",
        "axes[0].set_title(\"Probability distribution\")\n",
        "axes[0].set_xlabel(\"Probability\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "#axes[0].grid(which=\"major\")\n",
        "\n",
        "axes[1].plot(np.cumsum(np.sort(probs[0])[::-1]), color=\"black\")\n",
        "axes[1].set_xlim([0, 10000])\n",
        "axes[1].set_ylim([0.75, 1.01])\n",
        "axes[1].set_title(\"Cumulative probability\")\n",
        "axes[1].set_ylabel(\"Probability\")\n",
        "axes[1].set_xlabel(\"Token (descending probability)\")\n",
        "#axes[1].grid(which=\"major\")\n",
        "axes[1].minorticks_on()\n",
        "#axes[1].grid(which='minor', linewidth='0.5')\n",
        "top_k_label = 'top-k threshold (k=2000)'\n",
        "top_p_label = 'nucleus threshold (p=0.95)'\n",
        "axes[1].vlines(x=2000, ymin=0, ymax=2, color='C0', label=top_k_label)\n",
        "axes[1].hlines(y=0.95, xmin=0, xmax=10000, color='C1', label=top_p_label, linestyle='--')\n",
        "axes[1].legend(loc='lower right')\n",
        "plt.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}